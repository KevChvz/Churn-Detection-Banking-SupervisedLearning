# Detecci√≥n de deserci√≥n de clientes en el sector bancario utilizando aprendizaje supervisado

## Objetivo General del Proyecto üòÉ
Evaluar el desempe√±o del m√©todo de sobremuestreo SMOTE, el m√©todo de submuestreo RUS y los m√©todos de sobremuestreo seguido de submuestreo SMOTE+ENN y SMOTE+TOMEK, utilizando los algoritmos de clasificaci√≥n XGBoost, LogisticRegression, SVM, Random Forest, Naive Bayes, Decision Tree y KNN en 7 datasets desbalanceados obtenidos de los pa√≠ses de Espa√±a, Francia y Alemania en t√©rminos precisi√≥n, sensibilidad, exactitud, valor-F1 y √°rea bajo la curva ROC.

## Objetivos Espec√≠ficos del Proyecto üßê
- OE1: Analizar las fortalezas y limitaciones de los algoritmos de clasificaci√≥n como RandomForest, SVM, XGboost, LogisticRegression, Naive Bayes, Decision Tree y KNN; y m√©todos de desbalanceo como SMOTE, RUS, SMOTE+ENN y SMOTE+TOMEK utilizados en estudios anteriores.
- OE2: Dise√±ar un metodo de comparacion para identificar los mejores modelos con respecto a los algoritmos Random Forest, XGBoost, LogisticRegression, SVM, Naive Bayes, Decision Tree y KNN explorando los par√°metros de los m√©todos de balanceo SMOTE, RUS, SMOTE+ENN y SMOTE+TOMEK y explorar la fusi√≥n de los datasets Espa√±a, Francia y Alemania en variantes.
- OE3: Evaluar los m√©todos de remuestreo SMOTE, RUS, SMOTE+ENN, SMOTE+TOMEK para determinar la t√©cnica m√°s adecuada en base a las m√©tricas Precision (precisi√≥n), Recall (sensibilidad), Accuracy (exactitud), F-measure (medida F1) y AUC(√Årea bajo la curva)
- OE4: Evaluar los diversos modelos obtenidos a partir de los algoritmos de clasificaci√≥n Random Forest, XGBoost, LogisticRegression, SVM, Naive Bayes, Decision Tree y KNN para identificar el mejor modelo en base a las m√©tricas Precision (precisi√≥n), Recall (sensibilidad), Accuracy (exactitud), F-measure (medida F1) y AUC(√Årea bajo la curva)
- OE5: Comparar el desempe√±o de los clasificadores Random Forest, XGBoost, LogisticRegression, SVM, Naive Bayes, Decision Tree y KNN versus los m√©todos de remuestreo SMOTE, RUS, SMOTE+ENN y SMOTE+TOMEK  sobre 7 variantes de datasets a partir de los 3 escenarios: Espa√±a, Alemania y Francia en t√©rminos de Precision (precisi√≥n), Recall (sensibilidad), Accuracy (exactitud), F-measure (medida F1) y AUC(√Årea bajo la curva)

## M√©todo propuesto üíØ
Proponemos una comparativa, de los algoritmos con mejor desempe√±o presentado en la literatura, Extreme Gradient Boosting (XGBoost), Random Forest, SVM, Regresi√≥n Log√≠stica , Naive Bayes, Decision Tree y KNN Combin√°ndolos con el m√©todo de submuestreo RUS, el m√©todo de sobremuestreo SMOTE, y los m√©todos de sobremuestreo seguidos de submmuestreo SMOTE-ENN y SMOTE-TOMEK para evaluar su comportamiento frente a 7 escenarios diferentes, con conjuntos de datos de Alemania, Espa√±a, Francia y Alemania-Espa√±a, Espa√±a-Francia y Alemania-Francia. Ya que es probable que cada algoritmo presente un desempe√±o mejor en cada escenario, en base al m√©todo con el que se combine para lidiar con el problema de los datos desbalanceados en t√©rminos de precisi√≥n, sensibilidad, exactitud y valor-F1.

## Lista de Actividades realizadas para el proyecto ‚≠ê üíª
- Extracci√≥n del dataset de Kaggle
- Entendimiento del dataset (componentes y registros)
- Preparaci√≥n de los datos (filtros, modificaciones y eliminaciones)
- Escalamiento de los datos (Reemplazar por rangos entre 0 y 1)
- Separaci√≥n del dataset general en 7 dataset espec√≠ficos (dataset de Francia, Espa√±a, Alemania, Francia+Alemania, Francia+Espa√±a, Alemania+Espa√±a y Francia+Alemania+Espa√±a)
- Gr√°fico pie chart para visualizar el desbalanceo por cada dataset
- Aplicaci√≥n de los m√©todos RUS, SMOTE, SMOTE+ENN y SMOTE+TOMEK en cada uno de los datasets
- Aplicaci√≥n del algoritmo XGBoost
- Aplicaci√≥n de los algoritmos de predicci√≥n XGBoost, Random Forest, SVM, LogisticRegression, Naive Bayes, Decision Tree y KNN en cada uno de los escenarios resultado de las t√©cnicas de muestreo en cada dataset.
- Evaluar en base a las m√©tricas cada resultado obtenido en cada conjunto de algoritmo+t√©cnica de remuestreo+dataset

## Lista de m√©tricas ‚ö°
- Precisi√≥n
- Exhaustividad
- Exactitud
- Valor F1
- √Årea bajo la curva ROC (AUC)

---
## Pasos para ejecutar el aplicativo üìà
1. Clonar el proyecto 
2. Instalar las librerias ubicadas en el archivo paquetes.sh
3. Escoger python como lenguaje de interpretaci√≥n
4. Seleccionar un dataset (guiarse por el nombre del archivo .py) y ejecutarlo para obtener los resultados de las t√©cnicas RUS, SMOTE, SMOTE+ENN y SMOTE+TOMEK de ese dataset
5. Para ejecutar, en PyCharm en las opciones elegir Run > Run (Alt+M√°yus+F10) y seleccionar el "Run Configuracion" por defecto  
6. Los archivos que empiezan por Dataset son derivados del proyecto principal PrototipoGrupo2.
7. En prototipogrupo2 se encuentra la preparaci√≥n de datos y la separaci√≥n de datasets de acuerdo a los pa√≠ses y se grafica los piechart que muestran la data desbalanceada.
8. En los archivos que empiezan con Dataset, en cada uno de estos se aplica los m√©todos de remuestreo, y en cada uno de los m√©todos aplicado en cada escenario se muestra un gr√°fico de barras de la versi√≥n antes de aplicar el m√©todo y luego de aplicado el m√©todo.

## Contribuidoresü§ù
- Kevin Ch√°vez
- Kevin Humareda
- Pedro Shiguihara
